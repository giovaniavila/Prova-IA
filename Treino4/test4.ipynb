{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bff8ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral 7B\\nAlbert Q. Jiang, Alexandre Sablayr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>automated benchmarks. Our models are released ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GQA significantly accelerates the inference sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mistral 7B takes a significant step in balanci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parameters of the architecture are summarized ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk\n",
       "0  Mistral 7B\\nAlbert Q. Jiang, Alexandre Sablayr...\n",
       "1  automated benchmarks. Our models are released ...\n",
       "2  GQA significantly accelerates the inference sp...\n",
       "3  Mistral 7B takes a significant step in balanci...\n",
       "4  parameters of the architecture are summarized ..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precisamos extrair os dados desse csv, para isso, irei utilizar do pandas para a leitura desse csv\n",
    "# é uma das melhores opcoes para se trabalhar com leitura de csvs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"hf://datasets/infoslack/mistral-7b-arxiv-paper-chunked/train.jsonl\", lines=True)\n",
    "\n",
    "df[[\"chunk\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a7dcd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9eb2cf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mistral', 'albert', 'jiang', 'Alexandre', 'sablayrolles', 'arthur', 'Mensch', 'chri', 'Bamford', 'Devendra', 'Singh', 'chaplot', 'diego', 'Las', 'casa', 'Florian', 'bressand', 'gianna', 'Lengyel', 'guillaume', 'lample', 'lucile', 'saulnier', 'lélio', 'renard', 'lavaud', 'Lachaux', 'pierrer', 'stock', 'teven', 'Le', 'scao', 'thibaut', 'lavril', 'thoma', 'Wang', 'timothée', 'lacroix', 'William', 'el', 'sayed', 'abstract', 'we', 'introduce', 'mistral', 'language', 'Model', 'engineered', 'alto', 'performance', 'and', 'efficiency', 'mistral', 'outperforms', 'The', 'best', 'Open', 'model', 'llama', 'Across', 'All', 'evaluated', 'benchmarks', 'and', 'The', 'best', 'released', 'model', 'llama', 'In', 'reasoning', 'mathematics', 'and', 'coder', 'Generation', 'our', 'model', 'leverages', 'Attention', 'gqa', 'faster', 'inference', 'coupled', 'with', 'sliding', 'Window', 'Attention', 'swa', 'to', 'effectively', 'handle', 'sequence', 'of', 'Arbitrary', 'Length', 'With', 'reduced', 'inferencer', 'cost', 'we', 'also', 'providir', 'model', 'to', 'Follow', 'instructiom', 'mistral', 'instruct', 'that', 'surpasses', 'llama', 'chat', 'model', 'both', 'on', 'human', 'and', 'automatedr', 'benchmarks', 'our', 'models', 'are', 'released', 'under', 'the', 'apache', 'license', 'coder']\n",
      "['automatedr', 'benchmarks', 'our', 'models', 'are', 'released', 'under', 'the', 'apache', 'license', 'coder', 'Webpage', 'introduction', 'in', 'the', 'rapidly', 'Evolving', 'domain', 'of', 'natural', 'language', 'processing', 'nlp', 'the', 'race', 'towards', 'higher', 'model', 'performancer', 'often', 'necessitate', 'an', 'escalation', 'In', 'model', 'size', 'however', 'thi', 'scaling', 'tends', 'to', 'increase', 'computational', 'costs', 'and', 'inference', 'latency', 'thereby', 'Raising', 'Barriers', 'to', 'deployment', 'in', 'practical', 'scenario', 'in', 'thi', 'context', 'the', 'search', 'balanced', 'models', 'delivering', 'both', 'performance', 'and', 'efficiency', 'Becomes', 'critically', 'essential', 'our', 'model', 'mistral', 'demonstrate', 'that', 'carefully', 'designed', 'language', 'Model', 'can', 'deliver', 'high', 'performance', 'while', 'Maintaining', 'an', 'efficient', 'inference', 'mistral', 'outperforms', 'the', 'previous', 'best', 'model', 'llama', 'Across', 'All', 'testedr', 'benchmarks', 'and', 'surpasses', 'The', 'best', 'model', 'llama', 'In', 'mathematics', 'and', 'coder', 'Generation', 'furthermore', 'mistral', 'approaches', 'The', 'coding', 'Performance', 'of', 'without', 'sacrificing', 'Performance', 'on', 'related', 'benchmarks', 'mistral', 'leverages', 'Attention', 'gqa', 'and', 'sliding', 'Window', 'Attention', 'swa', 'gqa', 'significantly', 'accelerate', 'The', 'inference', 'speed', 'and', 'also', 'reduce', 'The', 'memory', 'requirement', 'during']\n",
      "['Gqa', 'significantly', 'accelerate', 'The', 'inference', 'speed', 'and', 'also', 'reduce', 'The', 'memory', 'requirement', 'during', 'decoding', 'allowing', 'higher', 'batch', 'siz', 'hence', 'higher', 'throughput', 'crucial', 'factor', 'applicatiom', 'in', 'Addition', 'Swa', 'is', 'designed', 'to', 'handle', 'longer', 'sequence', 'more', 'effectively', 'at', 'reduced', 'computational', 'costr', 'thereby', 'alleviatingr', 'common', 'limitation', 'in', 'llms', 'these', 'Attention', 'mechanism', 'collectively', 'contribute', 'to', 'the', 'enhanced', 'Performance', 'and', 'efficiency', 'of', 'mistral', 'octer', 'mistral', 'is', 'released', 'under', 'the', 'apache', 'license', 'this', 'release', 'is', 'accompaniedr', 'by', 'reference', 'easy', 'deployment', 'either', 'locally', 'or', 'on', 'cloud', 'platforms', 'such', 'aws', 'gcp', 'or', 'azure', 'using', 'The', 'vllm', 'inferencer', 'server', 'and', 'Integration', 'with', 'Hugging', 'also', 'streamlined', 'easier', 'Integration', 'moreover', 'mistral', 'is', 'crafted', 'ease', 'of', 'across', 'myriad', 'of', 'tasks', 'demonstration', 'of', 'its', 'adaptability', 'and', 'superior', 'performance', 'we', 'present', 'chat', 'model', 'from', 'mistral', 'that', 'significantly', 'outperforms', 'The', 'llamar', 'chat', 'model', 'mistral', 'takes', 'significant', 'step', 'in', 'balancing', 'the', 'Goals', 'of', 'Getting', 'high', 'performance', 'while', 'keeping', 'Large', 'language', 'Models', 'efficient', 'through', 'our', 'Work', 'our', 'aim', 'is', 'to', 'help', 'the', 'community', 'create', 'more']\n",
      "['mistral', 'takes', 'significant', 'step', 'in', 'balancing', 'the', 'Goals', 'of', 'Getting', 'high', 'performance', 'while', 'keeping', 'Large', 'language', 'Models', 'efficient', 'through', 'our', 'Work', 'our', 'aim', 'is', 'to', 'help', 'the', 'community', 'create', 'more', 'affordable', 'efficient', 'and', 'language', 'Models', 'that', 'Can', 'be', 'used', 'in', 'wide', 'rangir', 'of', 'applicatiom', 'architectural', 'details', 'figure', 'sliding', 'Window', 'Attention', 'the', 'number', 'of', 'operations', 'In', 'vanillar', 'Attention', 'is', 'quadratic', 'in', 'the', 'sequence', 'Length', 'and', 'The', 'memory', 'increase', 'linearly', 'with', 'the', 'number', 'of', 'tokem', 'at', 'inference', 'time', 'thi', 'incurs', 'higher', 'latency', 'and', 'smaller', 'throughput', 'due', 'to', 'reduced', 'Cache', 'availability', 'to', 'alleviate', 'thi', 'issue', 'we', 'use', 'sliding', 'Window', 'attention', 'each', 'token', 'can', 'attend', 'to', 'at', 'most', 'wtokens', 'from', 'the', 'previous', 'layer', 'here', 'note', 'that', 'tokem', 'outside', 'The', 'sliding', 'Window', 'still', 'influencer', 'next', 'Word', 'prediction', 'at', 'each', 'Attention', 'layerr', 'information', 'Can', 'mover', 'forward', 'by', 'wtokem', 'hence', 'after', 'Kattention', 'layer', 'information', 'Can', 'mover', 'Forward', 'by', 'up', 'to', 'parameter', 'value', 'dim', 'table', 'model', 'is', 'Based', 'on', 'transformer', 'architecture', 'the', 'Main', 'parameters', 'of', 'the', 'architecturar', 'are', 'summarized', 'in', 'table', 'compared', 'to', 'llama', 'it', 'introduce', 'few', 'Changes', 'that', 'we', 'summarizar', 'below']\n",
      "['parameter', 'of', 'the', 'architecturar', 'are', 'summarized', 'in', 'table', 'compared', 'to', 'llama', 'it', 'introduce', 'few', 'Changes', 'that', 'we', 'summarizar', 'below', 'Sliding', 'Window', 'Attention', 'swa', 'exploit', 'the', 'stacked', 'layers', 'of', 'transformer', 'to', 'attend', 'Information', 'Beyond', 'The', 'Window', 'size', 'the', 'hidden', 'state', 'in', 'position', 'iof', 'The', 'layerr', 'k', 'hi', 'Attends', 'to', 'All', 'hidden', 'states', 'from', 'the', 'previous', 'layer', 'with', 'positiom', 'between', 'recursively', 'hican', 'Access', 'tokem', 'from', 'the', 'input', 'layer', 'at', 'distance', 'of', 'up', 'to', 'tokem', 'illustrated', 'in', 'figurar', 'at', 'The', 'Last', 'Layer', 'using', 'window', 'sizar', 'we', 'haver', 'theoretical', 'Attention', 'Span', 'of', 'approximately', 'in', 'practice', 'sequence', 'Length', 'of', 'and', 'changes', 'made', 'to', 'Flashattention', 'and', 'xformer', 'yield', 'speed', 'improvement', 'over', 'vanilla', 'Attention', 'baseline', 'rolling', 'buffer', 'cache', 'fixed', 'Attention', 'Span', 'means', 'that', 'we', 'can', 'limit', 'our', 'cache', 'size', 'using', 'rolling', 'buffer', 'cache', 'the', 'cache', 'has', 'fixed', 'size', 'of', 'w', 'and', 'the', 'Keys', 'and', 'value', 'The', 'timestep', 'iare', 'stored', 'in', 'position', 'imodwof', 'the', 'Cache', 'result', 'When', 'the', 'position', 'iis', 'larger', 'than', 'w', 'pastr', 'value', 'in', 'the', 'cache', 'are', 'overwritten', 'and', 'the', 'size', 'of', 'the', 'Cache', 'stop', 'increasing', 'we', 'providir', 'an', 'illustration', 'in', 'figure', 'on', 'sequence', 'Length', 'of', 'tokem', 'thi', 'reduce', 'The', 'Cache', 'memory', 'usage']\n",
      "['in', 'figurar', 'on', 'sequence', 'Length', 'of', 'tokem', 'thi', 'reduce', 'The', 'Cache', 'memory', 'usage', 'by', 'without', 'impacting', 'the', 'model', 'quality', 'figure', 'Rolling', 'buffer', 'Cache', 'the', 'cache', 'has', 'fixed', 'size', 'of', 'keys', 'and', 'value', 'position', 'iare', 'stored', 'in', 'position', 'imod', 'wof', 'the', 'Cache', 'when', 'the', 'position', 'iis', 'larger', 'than', 'w', 'pastr', 'value', 'in', 'the', 'cache', 'are', 'overwritten', 'the', 'hidden', 'state', 'corresponding', 'to', 'The', 'latest', 'generated', 'tokem', 'are', 'colored', 'in', 'orange', 'and', 'chunking', 'When', 'Generating', 'sequence', 'we', 'need', 'to', 'predict', 'tokem', 'each', 'token', 'is', 'conditioned', 'on', 'The', 'previous', 'one', 'however', 'the', 'Prompt', 'is', 'Known', 'in', 'advancer', 'and', 'we', 'can', 'the', 'k', 'v', 'cache', 'with', 'the', 'Prompt', 'if', 'the', 'Prompt', 'is', 'very', 'Large', 'we', 'can', 'chunk', 'it', 'Into', 'smaller', 'piece', 'and', 'the', 'cache', 'With', 'each', 'chunk', 'thi', 'purpose', 'we', 'can', 'select', 'the', 'Window', 'sizar', 'our', 'chunk', 'size', 'each', 'chunk', 'we', 'thus', 'need', 'to', 'compute', 'the', 'Attention', 'over', 'the', 'Cache', 'and', 'over', 'the', 'chunk', 'figure', 'show', 'how', 'The', 'Attention', 'mask', 'works', 'over', 'both', 'the', 'cache', 'and', 'the', 'chunk']\n",
      "['chunk', 'figure', 'show', 'how', 'The', 'Attention', 'mask', 'works', 'over', 'both', 'the', 'cache', 'and', 'the', 'chunk', 'figurar', 'and', 'chunking', 'during', 'of', 'the', 'Cache', 'long', 'sequence', 'are', 'chunked', 'to', 'limit', 'memory', 'usage', 'we', 'process', 'sequence', 'in', 'three', 'chunk', 'the', 'cat', 'sat', 'on', 'the', 'mat', 'and', 'saw', 'the', 'dog', 'go', 'to', 'the', 'figurar', 'show', 'what', 'happem', 'The', 'third', 'chunk', 'the', 'dog', 'go', 'to', 'it', 'attends', 'itself', 'using', 'causal', 'mask', 'rightmost', 'block', 'attends', 'the', 'Cache', 'using', 'Sliding', 'Window', 'center', 'block', 'and', 'does', 'Not', 'attend', 'to', 'pastr', 'tokem', 'they', 'are', 'outside', 'of', 'the', 'sliding', 'Window', 'Left', 'block', 'results', 'we', 'compare', 'mistral', 'to', 'llama', 'and', 'All', 'benchmarks', 'with', 'our', 'own', 'evaluation', 'pipeline', 'fair', 'comparison', 'we', 'measure', 'performance', 'on', 'wide', 'variety', 'of', 'tasks', 'categorized', 'follow', 'reasoning', 'hellaswag', 'winogrande', 'piqa', 'siqa', 'openbookqa', 'commonsenseqa', 'Knowledge', 'naturalquestions', 'triviaqa']\n",
      "['Knowledge', 'naturalquestions', 'triviaqa', 'comprehension', 'boolq', 'quac', 'with', 'and', 'math', 'with', 'humaneval', 'and', 'mbpp', 'aggregated', 'results', 'mmlu', 'bbh', 'and', 'agi', 'eval', 'english', 'questions', 'only', 'detailed', 'results', 'mistral', 'llama', 'and', 'are', 'reported', 'in', 'table', 'figure', 'compare', 'the', 'Performance', 'of', 'mistral', 'with', 'llamar', 'and', 'llama', 'in', 'different', 'categorie', 'mistral', 'surpasses', 'llama', 'across', 'All', 'Metrics', 'and', 'outperforms', 'llama', 'on', 'most', 'benchmarks', 'in', 'particular', 'mistral', 'display', 'Superior', 'performance', 'in', 'coder', 'mathematics', 'and', 'reasoning', 'benchmarks', 'llama', 'was', 'Not', 'we', 'reportr', 'results', 'llama']\n",
      "['and', 'reasoning', 'benchmarks', 'llama', 'was', 'Not', 'we', 'reportr', 'results', 'llama', 'figure', 'performance', 'of', 'mistral', 'and', 'Different', 'Llama', 'Models', 'on', 'Wide', 'rangir', 'of', 'benchmarks', 'all', 'Models', 'Were', 'on', 'All', 'Metrics', 'with', 'our', 'evaluation', 'pipelinir', 'accurate', 'comparison', 'mistral', 'significantly', 'outperforms', 'llama', 'and', 'llama', 'on', 'All', 'benchmarks', 'it', 'is', 'also', 'vastly', 'Superior', 'to', 'llama', 'in', 'mathematics', 'coder', 'Generation', 'and', 'reasoning', 'benchmarks', 'model', 'modality', 'mmlu', 'hellaswag', 'Winog', 'Piqa', 'nq', 'triviaqa', 'humaneval', 'mbpp', 'math', 'llama', 'pretrained', 'llama', 'pretrained']\n",
      "['finetuned', 'mistral', 'pretrained', 'table', 'comparison', 'of', 'mistral', 'with', 'llama', 'mistral', 'outperforms', 'llama', 'on', 'All', 'Metrics', 'and', 'approaches', 'The', 'coder', 'performance', 'of', 'without', 'sacrificing', 'Performance', 'on', 'benchmarks', 'size', 'and', 'efficiency', 'we', 'computed', 'equivalent', 'model', 'siz', 'of', 'the', 'llamar', 'family', 'aiming', 'to', 'understand', 'mistral', 'models', 'efficiency', 'in', 'the', 'spectrum', 'see', 'figure', 'when', 'evaluated', 'on', 'reasoning', 'comprehension', 'and', 'stir', 'reasoning', 'specifically', 'mmlu', 'mistral', 'mirrored', 'performance', 'that', 'one', 'might', 'expect', 'from', 'llama', 'model', 'With', 'more', 'than', 'its', 'size', 'on', 'the', 'knowledge', 'benchmarks', 'mistral', 'performance', 'achieves', 'lower', 'compression', 'rate', 'of', 'which', 'is', 'likely', 'due', 'to', 'its', 'limited', 'parameter', 'count', 'that', 'restrictsr', 'The', 'amount', 'of', 'Knowledge', 'it', 'can', 'store']\n",
      "['Which', 'is', 'likely', 'due', 'to', 'its', 'limited', 'parameter', 'count', 'that', 'restrictsr', 'The', 'amount', 'of', 'Knowledge', 'it', 'can', 'store', 'evaluation', 'difference', 'on', 'some', 'benchmarks', 'there', 'Are', 'some', 'difference', 'Between', 'our', 'evaluation', 'protocol', 'and', 'the', 'one', 'reported', 'in', 'the', 'llamar', 'paper', 'on', 'mbpp', 'we', 'usar', 'the', 'subset', 'on', 'Triviaqa', 'we', 'Not', 'providir', 'wikipedia', 'contexts', 'instruction', 'finetuning', 'modelchatbotr', 'arena', 'elo', 'ratingmt', 'bench', 'wizardlm', 'mistral', 'instruct', 'llama', 'chat', 'vicuna', 'llama', 'chat', 'vicuna', 'alpacar', 'table', 'comparison', 'of', 'chat', 'models', 'mistral', 'instruct', 'outperforms', 'all', 'models', 'on', 'and', 'is', 'comparable', 'to', 'chat', 'evaluate', 'The', 'generalization', 'capabilitie', 'of', 'mistral', 'we', 'it', 'on', 'instruction', 'datasets', 'publicly', 'available', 'on', 'The', 'hugging', 'face', 'repositoryr', 'proprietary', 'data', 'or', 'training', 'tricks', 'Were', 'utilized', 'mistral', 'instruct', 'Model', 'is', 'simple', 'and', 'preliminary', 'demonstration', 'that', 'the', 'base', 'model', 'can', 'easily', 'be', 'to', 'achiever', 'Good', 'performance', 'in', 'table', 'we', 'observir', 'that', 'the', 'resulting', 'model']\n",
      "['preliminary', 'demonstration', 'that', 'the', 'base', 'model', 'can', 'easily', 'be', 'to', 'achiever', 'Good', 'performance', 'in', 'table', 'we', 'observir', 'that', 'the', 'resulting', 'model', 'mistral', 'instruct', 'exhibits', 'superior', 'performance', 'compared', 'to', 'All', 'models', 'on', 'and', 'is', 'comparable', 'to', 'chat', 'models', 'an', 'independent', 'human', 'evaluation', 'Was', 'conducted', 'on', 'in', 'thi', 'evaluation', 'participants', 'werir', 'provided', 'With', 'set', 'of', 'questiom', 'along', 'With', 'anonymous', 'response', 'from', 'two', 'Models', 'and', 'Were', 'asked', 'to', 'select', 'Their', 'preferred', 'response', 'illustrated', 'in', 'figurar', 'of', 'october', 'The', 'outputs', 'Generated', 'by', 'mistral', 'were', 'preferred', 'time', 'compared', 'to', 'time', 'llama', 'figure', 'results', 'on', 'mmlu', 'commonsense', 'reasoning', 'world', 'Knowledge', 'and', 'reading', 'comprehension', 'mistral', 'and', 'llama', 'mistral', 'largely', 'outperforms', 'llama', 'on', 'All', 'evaluations', 'except', 'on', 'Knowledge', 'benchmarks', 'wherir', 'it', 'is', 'on', 'par', 'thi', 'is', 'likely', 'due', 'to', 'its', 'limited', 'parameter', 'count', 'Which', 'Limits', 'the', 'amount', 'of', 'Knowledge', 'it', 'can', 'Compress', 'adding', 'guardrails', 'applicatiom', 'the', 'abilityr', 'to', 'enforce', 'Guardrails', 'When', 'it', 'Comes', 'to', 'ai', 'Generation', 'is', 'important', 'applicatiom', 'in', 'thi', 'section', 'we', 'highlight', 'how', 'to', 'leverage', 'system', 'prompting', 'to', 'optionally', 'enforce', 'output']\n",
      "['The', 'abilityr', 'to', 'enforce', 'Guardrails', 'When', 'it', 'Comes', 'to', 'ai', 'Generation', 'is', 'important', 'applicatiom', 'in', 'thi', 'section', 'we', 'highlight', 'how', 'to', 'leverage', 'system', 'prompting', 'to', 'optionally', 'enforce', 'output', 'constraints', 'on', 'top', 'of', 'our', 'Models', 'additionally', 'we', 'showcase', 'The', 'abilityr', 'of', 'mistral', 'to', 'perform', 'Content', 'Moderation', 'Which', 'Can', 'be', 'Useful', 'to', 'enforce', 'quality', 'content', 'in', 'applicatiom', 'system', 'prompt', 'to', 'enforce', 'guardrails', 'we', 'introduce', 'system', 'Prompt', 'see', 'below', 'to', 'Guide', 'the', 'Model', 'to', 'generate', 'answer', 'Within', 'specified', 'guardrails', 'similar', 'to', 'The', 'work', 'done', 'with', 'llama', 'using', 'thi', 'prompt', 'allow', 'the', 'user', 'to', 'Move', 'on', 'the', 'pareto', 'front', 'of', 'model', 'utility', 'guardrails', 'enforcement', 'indicated', 'in', 'table', 'alway', 'assist', 'with', 'care', 'respect', 'and', 'truth', 'respond', 'With', 'utmostr', 'utility', 'yet', 'securely', 'avoid', 'harmful', 'unethical', 'prejudiced', 'or', 'negative', 'content', 'ensure', 'replies', 'promote', 'fairness', 'and', 'positivityr', 'guardrails', 'mt', 'bench', 'system', 'Prompt', 'llama', 'system', 'prompt', 'mistral', 'systir', 'Prompt', 'table', 'system', 'prompts', 'mean', 'official', 'mt', 'bench', 'score', 'over', 'iterations', 'with', 'standard', 'deviationr', 'mistral', 'instruct', 'Reference', 'llama', 'chat', 'reports', 'official', 'results', 'of', 'usar', 'set', 'of', 'Unsafe', 'prompts', 'evaluating', 'safety', 'with', 'the', 'recommended', 'system', 'prompt', 'the', 'model', 'properly', 'decline', 'to', 'answer', 'of', 'the', 'harmful', 'questions']\n",
      "['official', 'results', 'of', 'usar', 'set', 'of', 'Unsafe', 'prompts', 'evaluating', 'safety', 'with', 'the', 'recommended', 'system', 'prompt', 'the', 'model', 'properly', 'decline', 'to', 'answer', 'of', 'the', 'harmful', 'questions', 'an', 'illustration', 'we', 'providir', 'in', 'table', 'the', 'answers', 'of', 'both', 'mistral', 'instruct', 'and', 'llama', 'chat', 'to', 'the', 'question', 'how', 'to', 'Kill', 'linux', 'process', 'with', 'systir', 'promptsr', 'activated', 'we', 'observir', 'that', 'mistral', 'provide', 'correct', 'response', 'while', 'llama', 'decline', 'to', 'answer', 'note', 'that', 'on', 'thi', 'specific', 'question', 'both', 'models', 'answer', 'Correctly', 'When', 'systir', 'prompts', 'are', 'deactivated', 'content', 'moderation', 'With', 'mistral', 'instruct', 'can', 'be', 'used', 'content', 'moderator', 'The', 'model', 'itself', 'is', 'able', 'to', 'accurately', 'classify', 'user', 'Prompt', 'or', 'its', 'generated', 'answer', 'being', 'either', 'acceptable', 'or', 'falling', 'intar', 'one', 'of', 'the', 'following', 'categories', 'illegal', 'activitie', 'suchr', 'terrorism', 'child', 'abuse', 'or', 'fraud', 'hateful', 'harassing', 'or', 'violent', 'content', 'suchr', 'discrimination', 'or', 'bullying', 'unqualified', 'advice', 'instancer', 'in', 'legal', 'medical', 'or', 'financial', 'domaim', 'model', 'answer', 'mistral', 'instruct', 'with', 'mistral', 'systir', 'promptto', 'Kill', 'linux', 'process', 'you', 'can', 'usar', 'the', 'followed', 'by', 'The', 'process', 'id', 'pid', 'of', 'the', 'process', 'you', 'Want', 'to', 'terminate', 'example', 'to', 'Kill', 'process', 'With', 'pid', 'you', 'would', 'Run', 'The', 'command', 'kill', 'it', 'important', 'to', 'note', 'that', 'killing', 'process', 'can']\n",
      "['Would', 'Run', 'The', 'command', 'kill', 'it', 'important', 'to', 'note', 'that', 'killing', 'process', 'can', 'have', 'Unintended', 'consequence', 'so', 'it', 'generallyr', 'good', 'idea', 'to', 'only', 'kill', 'processe', 'that', 'you', 'are', 'certain', 'you', 'Want', 'to', 'terminate', 'additionally', 'it', 'generallyr', 'good', 'idea', 'to', 'use', 'the', 'with', 'Caution', 'it', 'Can', 'be', 'used', 'to', 'terminate', 'critical', 'systir', 'processes', 'that', 'are', 'necessary', 'The', 'operation', 'of', 'the', 'systir', 'llama', 'chat', 'with', 'llamar', 'systir', 'prompto', 'helpful', 'and', 'respectful', 'assistant', 'i', 'cannot', 'providir', 'information', 'on', 'how', 'to', 'Kill', 'linux', 'process', 'it', 'is', 'Not', 'appropriate', 'or', 'Ethical', 'to', 'intentionally', 'harmr', 'or', 'terminate', 'processe', 'it', 'can', 'Cause', 'damage', 'to', 'The', 'systir', 'and', 'potentially', 'result', 'in', 'datar', 'loss', 'additionally', 'it', 'is', 'important', 'to', 'respect', 'The', 'autonomy', 'and', 'security', 'of', 'other', 'user', 'processe', 'they', 'may', 'be', 'critical', 'to', 'Their', 'Work', 'or', 'personal', 'activitie', 'instead', 'i', 'suggest', 'that', 'you', 'explore', 'other', 'optiom', 'to', 'address', 'any', 'issues', 'or', 'concerns', 'you', 'may', 'have', 'table', 'comparison', 'Between', 'mistral', 'and', 'llama', 'systir', 'prompts', 'mistral', 'provide', 'the', 'right', 'answer', 'whereo', 'llama', 'decline', 'to', 'answer', 'to', 'The', 'question', 'how', 'to', 'Kill', 'linux', 'Process', 'to', 'so', 'we', 'designed', 'Prompt', 'that', 'makes', 'mistral', 'classify', 'Prompt', 'or', 'generated', 'answer', 'we', 'evaluatedr', 'on', 'our', 'manually', 'curated', 'and', 'balanced', 'Dataset', 'of', 'adversarial']\n",
      "['answer', 'we', 'evaluatedr', 'on', 'our', 'manually', 'curated', 'and', 'balanced', 'Dataset', 'of', 'adversarial', 'and', 'standard', 'prompts', 'and', 'Got', 'precision', 'of', 'recall', 'of', 'considering', 'acceptable', 'promptsr', 'positive', 'the', 'usar', 'case', 'Are', 'vast', 'from', 'moderating', 'Comments', 'on', 'social', 'media', 'or', 'forums', 'to', 'brand', 'monitoring', 'on', 'The', 'Internet', 'in', 'particular', 'the', 'end', 'user', 'is', 'able', 'to', 'select', 'Afterwards', 'Which', 'categories', 'to', 'effectively', 'filter', 'based', 'on', 'their', 'particular', 'conclusion', 'our', 'Work', 'on', 'mistral', 'demonstrate', 'that', 'language', 'Models', 'may', 'Compress', 'knowledge', 'more', 'than', 'what', 'was', 'previouslyr', 'thought', 'thi', 'opem', 'up', 'interesting', 'perspective', 'the', 'field', 'has', 'so', 'far', 'put', 'the', 'emphasi', 'on', 'scaling', 'law', 'in', 'dimensions', 'directly', 'associating', 'model', 'capabilitie', 'to', 'training', 'costr', 'in', 'the', 'probler', 'is', 'rather', 'dimensional', 'model', 'capabilities', 'training', 'cost', 'inference', 'cost', 'and', 'much', 'remaim', 'to', 'be', 'Explored', 'to', 'obtain', 'The', 'Best', 'performancer', 'with', 'the', 'smallest', 'possible', 'model', 'acknowledgements', 'we', 'are', 'grateful', 'to', 'coreweave', 'their', 'help', 'in', 'marshalling', 'our', 'cluster', 'we', 'thank', 'the', 'cineca', 'eurohpc', 'team', 'and', 'in', 'particular', 'the', 'Operators', 'Of', 'Leonardo', 'their', 'resource', 'and', 'help', 'we', 'thank', 'the', 'maintainers', 'of', 'Flashattention', 'vllm', 'xformer', 'skypilot', 'their', 'precious', 'assistance', 'in', 'implementing', 'New', 'featur', 'and', 'integrating', 'their', 'Solutions', 'into', 'ours', 'huge', 'thank', 'to', 'tri', 'dao', 'and', 'Daniel', 'hazizar', 'helping', 'include', 'mistral', 'related', 'Changes', 'to', 'Flashattention', 'and', 'xformer', 'on']\n",
      "['In', 'implementing', 'New', 'featur', 'and', 'integrating', 'their', 'Solutions', 'into', 'ours', 'huge', 'thank', 'to', 'tri', 'dao', 'and', 'Daniel', 'hazizar', 'helping', 'include', 'mistral', 'related', 'Changes', 'to', 'Flashattention', 'and', 'xformer', 'on', 'tight', 'schedule', 'we', 'thank', 'the', 'teams', 'of', 'hugging', 'face', 'aws', 'Gcp', 'azurer', 'ml', 'their', 'intense', 'help', 'in', 'Making', 'our', 'model', 'Compatible', 'everywherir', 'figure', 'human', 'evaluation', 'of', 'mistral', 'instruct', 'vs', 'llama', 'chat', 'Example', 'an', 'example', 'of', 'human', 'evaluation', 'from', 'the', 'question', 'asks', 'recommendatiom', 'of', 'Books', 'in', 'quantum', 'physics', 'llama', 'chat', 'recommendsr', 'general', 'Physics', 'book', 'while', 'mistral', 'instruct', 'recommendsr', 'More', 'Relevant', 'Book', 'on', 'quantum', 'Physics', 'and', 'Describes', 'in', 'the', 'contents', 'in', 'More', 'detail', 'reference', 'ainslie', 'jame', 'Michiel', 'jong', 'Yury', 'zemlyanskiy', 'federico', 'lebrón', 'and', 'sumit', 'sanghai', 'gqa', 'training', 'generalized', 'transformer', 'models', 'from', 'checkpoints', 'Arxiv', 'preprint', 'Austin', 'augustu', 'odena', 'maxwell', 'nye', 'maarten', 'bosma', 'henryk', 'Michalewski', 'david', 'dohan', 'ellen', 'jiang', 'carrie', 'cair', 'michael', 'terry', 'quoc', 'Le', 'et', 'al', 'progr', 'synthesi', 'with', 'large']\n",
      "['dohan', 'ellen', 'jiang', 'carrie', 'cair', 'michael', 'terry', 'quoc', 'Le', 'et', 'al', 'progr', 'synthesi', 'with', 'large', 'language', 'Models', 'Arxiv', 'preprint', 'beltagy', 'matthew', 'peter', 'and', 'arman', 'cohan', 'longformer', 'the', 'transformer', 'arxiv', 'preprint', 'bisk', 'rowan', 'zellers', 'jianfeng', 'gao', 'Yejin', 'choi', 'et', 'al', 'piqa', 'reasoning', 'about', 'physical', 'commonsense', 'in', 'natural', 'language', 'in', 'Proceedings', 'of', 'the', 'aaai', 'conference', 'on', 'artificial', 'intelligence', 'Chen', 'jerry', 'tworek', 'heewoo', 'jun', 'qiming', 'yuan', 'Henrique', 'ponde', 'Oliveira', 'Pinto', 'jared', 'kaplan', 'harri', 'edwards', 'yuri', 'burda', 'nichola', 'joseph', 'greg', 'Brockman', 'et', 'al', 'evaluating', 'large', 'language', 'models', 'trained', 'on', 'coder', 'Arxiv', 'preprint', 'child', 'scott', 'gray', 'alecr', 'radford', 'and', 'ilya', 'sutskever', 'generating', 'long', 'sequence', 'with', 'sparser', 'transformer', 'Arxiv', 'preprint']\n",
      "['sparser', 'transformer', 'Arxiv', 'preprint', 'choi', 'he', 'he', 'mohit', 'iyyer', 'Mark', 'yatskar', 'yih', 'Yejin', 'choi', 'percy', 'liang', 'and', 'luke', 'zettlemoyer', 'quac', 'question', 'answering', 'In', 'context', 'Arxiv', 'preprint', 'Clark', 'kenton', 'Lee', 'chang', 'tom', 'Kwiatkowski', 'michael', 'collim', 'and', 'kristina', 'toutanovo', 'boolq', 'exploring', 'the', 'surprising', 'difficulty', 'of', 'natural', 'yes', 'questions', 'Arxiv', 'preprint', 'clark', 'isaac', 'cowhey', 'oren', 'etzioni', 'tushar', 'khot', 'ashish', 'sabharwal', 'carissar', 'schoenick', 'and', 'oyvind', 'Tafjord', 'think', 'you', 'have', 'solved', 'question', 'answering', 'try', 'arc', 'the', 'reasoning', 'challenge', 'Arxiv', 'preprint', 'karl', 'Cobbe', 'vineet', 'kosaraju', 'mohammad', 'Bavarian', 'mark', 'Chen', 'heewoo', 'jun', 'lukaszr', 'kaiser', 'matthio', 'plappert', 'jerry', 'tworek', 'jacob', 'Hilton', 'reiichiro', 'nakano', 'et', 'al', 'training', 'verifiers', 'to']\n",
      "['matthio', 'plappert', 'jerry', 'tworek', 'jacob', 'Hilton', 'reiichiro', 'nakano', 'et', 'al', 'training', 'verifiers', 'to', 'solver', 'math', 'Word', 'problem', 'Arxiv', 'preprint', 'tri', 'dao', 'Daniel', 'y', 'Fu', 'Stefano', 'ermon', 'Atri', 'rudra', 'and', 'christopher', 'ré', 'flashattention', 'fast', 'and', 'exact', 'Attention', 'with', 'in', 'advance', 'in', 'neural', 'information', 'processing', 'system', 'dan', 'hendrycks', 'Collin', 'Burns', 'Steven', 'basart', 'Andy', 'zou', 'manta', 'mazeika', 'dawn', 'song', 'and', 'jacob', 'Steinhardt', 'measuring', 'massive', 'multitask', 'language', 'understanding', 'Arxiv', 'preprintr', 'dan', 'hendrycks', 'Collin', 'Burns', 'saurav', 'kadavath', 'Akul', 'arora', 'Steven', 'basart', 'ericr', 'tang', 'dawn', 'song', 'and', 'jacob', 'Steinhardt', 'measuring', 'mathematical', 'problem', 'Solving', 'with', 'the', 'math', 'Dataset', 'Arxiv', 'preprint', 'jordan', 'hoffmann', 'Sebastian', 'borgeaud', 'arthur', 'Mensch', 'elena', 'buchatskaya', 'trevor', 'cair', 'elizar', 'rutherford', 'diego', 'Las', 'casa', 'lisar', 'anne', 'hendrick', 'johanne', 'Welbl', 'Aidan', 'clark', 'thoma']\n",
      "['rutherford', 'diego', 'Las', 'casa', 'lisar', 'anne', 'hendrick', 'johanne', 'Welbl', 'Aidan', 'clark', 'thoma', 'hennigan', 'ericr', 'noland', 'katherine', 'millican', 'George', 'van', 'den', 'Driessche', 'bogdan', 'damoc', 'aureliar', 'Guy', 'simon', 'osindero', 'karén', 'simonyan', 'Erich', 'elsen', 'oriol', 'vinyals', 'Jack', 'rae', 'and', 'laurent', 'sifre', 'an', 'empirical', 'Analysis', 'of', 'Large', 'language', 'Model', 'training', 'in', 'advance', 'in', 'neural', 'Information', 'processing', 'system', 'volume', 'mandar', 'joshi', 'eunsol', 'choi', 'Daniel', 's', 'weld', 'and', 'Luke', 'zettlemoyer', 'triviaqa', 'large', 'scale', 'distantly', 'supervised', 'challenge', 'datasetr', 'reading', 'comprehension', 'Arxiv', 'preprint', 'tom', 'Kwiatkowski', 'jennimar', 'palomaki', 'oliver', 'redfield', 'michael', 'collim', 'Ankur', 'Parikh', 'chri', 'albertir', 'danielle', 'epstein', 'illia', 'polosukhin', 'Jacob', 'devlin', 'kenton', 'Lee', 'et', 'al', 'natural', 'questions', 'benchmark', 'question', 'answering', 'researchr', 'transactions', 'of', 'the', 'association', 'computational', 'linguistics', 'woosuk', 'Kwon', 'zhuohan', 'li', 'siyuan', 'zhuang', 'ying', 'sheng', 'Lianmin', 'zheng', 'cody', 'hao', 'yu']\n",
      "['woosuk', 'Kwon', 'zhuohan', 'li', 'siyuan', 'zhuang', 'ying', 'sheng', 'Lianmin', 'zheng', 'cody', 'hao', 'yu', 'joseph', 'Gonzalez', 'hao', 'zhang', 'and', 'ion', 'stoico', 'efficient', 'memoryr', 'management', 'large', 'language', 'Model', 'serving', 'with', 'pagedattention', 'in', 'Proceedings', 'of', 'the', 'acm', 'sigop', 'symposiumr', 'on', 'operating', 'systems', 'principle', 'Benjamin', 'lefaudeux', 'Francisco', 'Massa', 'diano', 'liskovich', 'wenhan', 'xiong', 'vittorio', 'caggiano', 'Sean', 'naren', 'min', 'xu', 'jieru', 'hu', 'marta', 'tintore', 'Susan', 'zhang', 'patrick', 'labatut', 'and', 'Daniel', 'haziza', 'xformer', 'modular', 'and', 'hackable', 'transformer', 'modelling', 'library', 'facebookresearch', 'xformer', 'todor', 'Mihaylov', 'peter', 'Clark', 'tushar', 'khot', 'and', 'ashish', 'sabharwal', 'can', 'Suit', 'of', 'armor', 'conduct', 'electricity', 'New', 'dataset', 'Open', 'Book', 'question', 'answering', 'Arxiv', 'preprint', 'baptiste', 'rozière', 'jona', 'Gehring', 'fabian', 'Gloeckle', 'sten', 'sootla', 'itai', 'gat', 'xiaoqing', 'ellen', 'tan']\n",
      "['baptiste', 'rozière', 'jona', 'Gehring', 'fabian', 'Gloeckle', 'sten', 'sootla', 'itai', 'gat', 'xiaoqing', 'ellen', 'tan', 'yossi', 'adi', 'jingyu', 'liu', 'remez', 'jérémy', 'rapin', 'et', 'al', 'coder', 'llama', 'Open', 'foundation', 'models', 'coder', 'Arxiv', 'preprinto', 'keisuke', 'Sakaguchi', 'Ronan', 'Le', 'bra', 'chandra', 'bhagavatula', 'and', 'yejin', 'choi', 'winogrande', 'an', 'adversarial', 'winograd', 'schema', 'challengir', 'at', 'scale', 'communications', 'of', 'The', 'acm', 'maarten', 'sap', 'hannah', 'rashkin', 'derek', 'chen', 'Ronan', 'lebro', 'and', 'yejin', 'choi', 'Socialiqa', 'Commonsense', 'reasoning', 'about', 'social', 'interactions', 'Arxiv', 'preprint', 'mirac', 'suzgun', 'nathan', 'scales', 'nathanael', 'schärli', 'sebastian', 'gehrmann', 'yi', 'Tay', 'hyung', 'Won', 'chung', 'Aakanksha', 'Chowdhery', 'quoc', 'v', 'Le', 'ed', 'h', 'chi', 'denny', 'zhar', 'and', 'jason', 'Wei', 'challenging', 'tasks', 'and', 'Whether', 'can', 'solver', 'them', 'arxiv', 'preprintr']\n",
      "['Challenging', 'tasks', 'and', 'Whether', 'can', 'solver', 'them', 'arxiv', 'preprintr', 'alon', 'Talmor', 'jonathan', 'herzig', 'nichola', 'lourie', 'and', 'jonathan', 'berant', 'commonsenseqa', 'question', 'answering', 'challengir', 'targeting', 'commonsense', 'knowledge', 'Arxiv', 'preprint', 'hugo', 'touvron', 'thibaut', 'lavril', 'gautier', 'izacard', 'xavier', 'Martinet', 'Lachaux', 'timothée', 'lacroix', 'baptiste', 'rozière', 'naman', 'goyalr', 'ericr', 'hambro', 'faisal', 'azhar', 'et', 'al', 'llama', 'Open', 'and', 'efficient', 'foundation', 'language', 'Models', 'Arxiv', 'preprint', 'hugo', 'touvron', 'louis', 'Martin', 'kevin', 'Stone', 'peter', 'Albert', 'amjad', 'almahairi', 'yasmine', 'babaei', 'nikolay', 'bashlykov', 'soumya', 'batro', 'prajjwal', 'bhargar', 'shruti', 'bhosale', 'et', 'al', 'llama', 'Open', 'foundation', 'and', 'chat', 'models', 'Arxiv', 'preprint']\n",
      "['foundation', 'and', 'chat', 'models', 'Arxiv', 'preprint', 'ashish', 'vaswani', 'noam', 'shazeer', 'niki', 'parmar', 'Jakob', 'uszkoreit', 'llion', 'Jones', 'aidan', 'n', 'gomez', 'łukaszr', 'kaiser', 'and', 'illia', 'polosukhin', 'Attention', 'is', 'All', 'you', 'need', 'advance', 'in', 'neural', 'information', 'processing', 'system', 'rowan', 'zellers', 'ari', 'holtzman', 'yonatan', 'bisk', 'farhadi', 'and', 'yejin', 'choi', 'hellaswag', 'can', 'machine', 'really', 'finish', 'Your', 'sentence', 'Arxiv', 'preprint', 'wanjun', 'zhong', 'ruixiang', 'cui', 'yiduo', 'guo', 'yaobo', 'liang', 'shuai', 'lu', 'yanlin', 'Wang', 'Amin', 'saied', 'Weizhu', 'Chen', 'and', 'nan', 'duan', 'agieval', 'benchmark', 'evaluating', 'foundation', 'models', 'Arxiv', 'preprint']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mistral 7B\\nAlbert Q. Jiang, Alexandre Sablayr...</td>\n",
       "      <td>mistral albert jiang Alexandre sablayrolles ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>automated benchmarks. Our models are released ...</td>\n",
       "      <td>automatedr benchmarks our models are released ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GQA significantly accelerates the inference sp...</td>\n",
       "      <td>Gqa significantly accelerate The inference spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mistral 7B takes a significant step in balanci...</td>\n",
       "      <td>mistral takes significant step in balancing th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parameters of the architecture are summarized ...</td>\n",
       "      <td>parameter of the architecturar are summarized ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chunk  \\\n",
       "0  Mistral 7B\\nAlbert Q. Jiang, Alexandre Sablayr...   \n",
       "1  automated benchmarks. Our models are released ...   \n",
       "2  GQA significantly accelerates the inference sp...   \n",
       "3  Mistral 7B takes a significant step in balanci...   \n",
       "4  parameters of the architecture are summarized ...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  mistral albert jiang Alexandre sablayrolles ar...  \n",
       "1  automatedr benchmarks our models are released ...  \n",
       "2  Gqa significantly accelerate The inference spe...  \n",
       "3  mistral takes significant step in balancing th...  \n",
       "4  parameter of the architecturar are summarized ...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apos realizadt a leitura, devemos limpar esses dados, ou seja, deixar somente valores\n",
    "# que possam agregar semanticamente para nosso contexto, removendo numeros, pontuacoes, espacos desnecessarios\n",
    "# dessa forma é possivel realizar uma melhor analise dos dados\n",
    "import spacy  # importa a biblioteca spaCy para processamento de linguagem natural\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")  # carrega o modelo de linguagem para português (pequeno)\n",
    "\n",
    "def preprocess(text):\n",
    "    if not isinstance(text, str):  # verifica se o input é uma string, senão retorna string vazia\n",
    "        return \"\"\n",
    "    doc = nlp(text.lower())  # converte o texto para minúsculas e processa com spaCy\n",
    "    # cria uma lista de lemas (forma base das palavras) filtrando tokens que são letras e não são stopwords\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]  \n",
    "    print(tokens)  # imprime os tokens lematizados para conferência\n",
    "    return \" \".join(tokens)  # retorna os tokens unidos em uma string novamente\n",
    "\n",
    "# aplica a função preprocess em cada texto da coluna 'resposta_aberta' e cria uma nova coluna 'processed_text'\n",
    "df[\"processed_text\"] = df[\"chunk\"].apply(preprocess)\n",
    "\n",
    "# imprime as primeiras linhas das colunas originais e processadas para comparar\n",
    "df[[\"chunk\", \"processed_text\"]].head()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82dc01c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mistral albert jiang Alexandre sablayrolles arthur Mensch chri Bamford', 'Mensch chri Bamford Devendra Singh chaplot diego Las casa Florian', 'Las casa Florian bressand gianna Lengyel guillaume lample lucile', 'lample lucile saulnier lélio renard lavaud Lachaux pierrer stock teven', 'pierrer stock teven Le scao thibaut lavril thoma Wang timothée lacroix', 'timothée lacroix William el sayed abstract we introduce mistral', 'we introduce mistral language Model engineered alto performance and', 'alto performance and efficiency mistral outperforms The best Open', 'The best Open model llama Across All evaluated benchmarks and The best', 'and The best released model llama In reasoning mathematics and coder', 'and coder Generation our model leverages Attention gqa faster', 'Attention gqa faster inference coupled with sliding Window Attention', 'Window Attention swa to effectively handle sequence of Arbitrary', 'of Arbitrary Length With reduced inferencer cost we also providir', 'we also providir model to Follow instructiom mistral instruct that', 'instruct that surpasses llama chat model both on human and automatedr', 'human and automatedr benchmarks our models are released under the', 'released under the apache license coder automatedr benchmarks our', 'benchmarks our models are released under the apache license coder', 'apache license coder Webpage introduction in the rapidly Evolving', 'the rapidly Evolving domain of natural language processing nlp the', 'processing nlp the race towards higher model performancer often', 'performancer often necessitate an escalation In model size however thi', 'size however thi scaling tends to increase computational costs and', 'costs and inference latency thereby Raising Barriers to deployment in', 'to deployment in practical scenario in thi context the search balanced', 'the search balanced models delivering both performance and efficiency', 'and efficiency Becomes critically essential our model mistral', 'our model mistral demonstrate that carefully designed language Model', 'language Model can deliver high performance while Maintaining an', 'while Maintaining an efficient inference mistral outperforms the', 'outperforms the previous best model llama Across All testedr', 'Across All testedr benchmarks and surpasses The best model llama In', 'best model llama In mathematics and coder Generation furthermore', 'furthermore mistral approaches The coding Performance of without', 'of without sacrificing Performance on related benchmarks mistral', 'benchmarks mistral leverages Attention gqa and sliding Window', 'and sliding Window Attention swa gqa significantly accelerate The', 'accelerate The inference speed and also reduce The memory requirement', 'memory requirement during Gqa significantly accelerate The inference', 'The inference speed and also reduce The memory requirement during', 'requirement during decoding allowing higher batch siz hence higher', 'siz hence higher throughput crucial factor applicatiom in Addition Swa', 'in Addition Swa is designed to handle longer sequence more effectively', 'more effectively at reduced computational costr thereby alleviatingr', 'thereby alleviatingr common limitation in llms these Attention', 'llms these Attention mechanism collectively contribute to the enhanced', 'to the enhanced Performance and efficiency of mistral octer mistral is', 'octer mistral is released under the apache license this release is', 'this release is accompaniedr by reference easy deployment either', 'deployment either locally or on cloud platforms such aws gcp or azure', 'aws gcp or azure using The vllm inferencer server and Integration with', 'and Integration with Hugging also streamlined easier Integration', 'easier Integration moreover mistral is crafted ease of across myriad', 'of across myriad of tasks demonstration of its adaptability and', 'its adaptability and superior performance we present chat model from', 'chat model from mistral that significantly outperforms The llamar chat', 'The llamar chat model mistral takes significant step in balancing the', 'in balancing the Goals of Getting high performance while keeping Large', 'while keeping Large language Models efficient through our Work our aim', 'our Work our aim is to help the community create more mistral takes', 'more mistral takes significant step in balancing the Goals of Getting', 'the Goals of Getting high performance while keeping Large language', 'Large language Models efficient through our Work our aim is to help', 'our aim is to help the community create more affordable efficient and', 'efficient and language Models that Can be used in wide rangir of', 'in wide rangir of applicatiom architectural details figure sliding', 'figure sliding Window Attention the number of operations In vanillar', 'In vanillar Attention is quadratic in the sequence Length and The', 'Length and The memory increase linearly with the number of tokem at', 'number of tokem at inference time thi incurs higher latency and', 'higher latency and smaller throughput due to reduced Cache', 'due to reduced Cache availability to alleviate thi issue we use', 'thi issue we use sliding Window attention each token can attend to at', 'can attend to at most wtokens from the previous layer here note that', 'layer here note that tokem outside The sliding Window still influencer', 'still influencer next Word prediction at each Attention layerr', 'Attention layerr information Can mover forward by wtokem hence after', 'wtokem hence after Kattention layer information Can mover Forward by', 'Can mover Forward by up to parameter value dim table model is Based on', 'model is Based on transformer architecture the Main parameters of the', 'parameters of the architecturar are summarized in table compared to', 'in table compared to llama it introduce few Changes that we summarizar', 'that we summarizar below parameter of the architecturar are summarized', 'are summarized in table compared to llama it introduce few Changes', 'few Changes that we summarizar below Sliding Window Attention swa', 'Window Attention swa exploit the stacked layers of transformer to', 'of transformer to attend Information Beyond The Window size the hidden', 'size the hidden state in position iof The layerr k hi Attends to All', 'k hi Attends to All hidden states from the previous layer with', 'previous layer with positiom between recursively hican Access tokem', 'hican Access tokem from the input layer at distance of up to tokem', 'of up to tokem illustrated in figurar at The Last Layer using window', 'Layer using window sizar we haver theoretical Attention Span of', 'Attention Span of approximately in practice sequence Length of and', 'Length of and changes made to Flashattention and xformer yield speed', 'xformer yield speed improvement over vanilla Attention baseline', 'Attention baseline rolling buffer cache fixed Attention Span means', 'Attention Span means that we can limit our cache size using rolling', 'size using rolling buffer cache the cache has fixed size of w and the', 'size of w and the Keys and value The timestep iare stored in position', 'stored in position imodwof the Cache result When the position iis', 'the position iis larger than w pastr value in the cache are', 'in the cache are overwritten and the size of the Cache stop increasing', 'stop increasing we providir an illustration in figure on sequence', 'figure on sequence Length of tokem thi reduce The Cache memory usage', 'Cache memory usage in figurar on sequence Length of tokem thi reduce', 'of tokem thi reduce The Cache memory usage by without impacting the', 'impacting the model quality figure Rolling buffer Cache the cache has', 'Cache the cache has fixed size of keys and value position iare stored', 'position iare stored in position imod wof the Cache when the position', 'when the position iis larger than w pastr value in the cache are', 'in the cache are overwritten the hidden state corresponding to The', 'corresponding to The latest generated tokem are colored in orange and', 'in orange and chunking When Generating sequence we need to predict', 'we need to predict tokem each token is conditioned on The previous one', 'on The previous one however the Prompt is Known in advancer and we can', 'advancer and we can the k v cache with the Prompt if the Prompt is', 'if the Prompt is very Large we can chunk it Into smaller piece and the', 'piece and the cache With each chunk thi purpose we can select the', 'we can select the Window sizar our chunk size each chunk we thus need', 'chunk we thus need to compute the Attention over the Cache and over', 'the Cache and over the chunk figure show how The Attention mask works', 'Attention mask works over both the cache and the chunk chunk figure', 'chunk chunk figure show how The Attention mask works over both the', 'works over both the cache and the chunk figurar and chunking during of', 'chunking during of the Cache long sequence are chunked to limit memory', 'to limit memory usage we process sequence in three chunk the cat sat', 'chunk the cat sat on the mat and saw the dog go to the figurar show', 'to the figurar show what happem The third chunk the dog go to it', 'the dog go to it attends itself using causal mask rightmost block', 'mask rightmost block attends the Cache using Sliding Window center', 'Window center block and does Not attend to pastr tokem they are', 'pastr tokem they are outside of the sliding Window Left block results', 'Left block results we compare mistral to llama and All benchmarks with', 'All benchmarks with our own evaluation pipeline fair comparison we', 'fair comparison we measure performance on wide variety of tasks', 'variety of tasks categorized follow reasoning hellaswag winogrande', 'hellaswag winogrande piqa siqa openbookqa commonsenseqa Knowledge', 'Knowledge naturalquestions triviaqa Knowledge naturalquestions', 'naturalquestions triviaqa comprehension boolq quac with and math with', 'with and math with humaneval and mbpp aggregated results mmlu bbh and', 'results mmlu bbh and agi eval english questions only detailed results', 'detailed results mistral llama and are reported in table figure', 'in table figure compare the Performance of mistral with llamar and', 'with llamar and llama in different categorie mistral surpasses llama', 'surpasses llama across All Metrics and outperforms llama on most', 'llama on most benchmarks in particular mistral display Superior', 'display Superior performance in coder mathematics and reasoning', 'and reasoning benchmarks llama was Not we reportr results llama and', 'results llama and reasoning benchmarks llama was Not we reportr', 'was Not we reportr results llama figure performance of mistral and', 'of mistral and Different Llama Models on Wide rangir of benchmarks all', 'of benchmarks all Models Were on All Metrics with our evaluation', 'with our evaluation pipelinir accurate comparison mistral', 'comparison mistral significantly outperforms llama and llama on All', 'and llama on All benchmarks it is also vastly Superior to llama in', 'Superior to llama in mathematics coder Generation and reasoning', 'and reasoning benchmarks model modality mmlu hellaswag Winog Piqa nq', 'Winog Piqa nq triviaqa humaneval mbpp math llama pretrained llama', 'pretrained llama pretrained finetuned mistral pretrained table', 'pretrained table comparison of mistral with llama mistral outperforms', 'mistral outperforms llama on All Metrics and approaches The coder', 'approaches The coder performance of without sacrificing Performance on', 'Performance on benchmarks size and efficiency we computed equivalent', 'computed equivalent model siz of the llamar family aiming to', 'family aiming to understand mistral models efficiency in the spectrum', 'in the spectrum see figure when evaluated on reasoning comprehension', 'comprehension and stir reasoning specifically mmlu mistral mirrored', 'mistral mirrored performance that one might expect from llama model', 'from llama model With more than its size on the knowledge benchmarks', 'knowledge benchmarks mistral performance achieves lower compression', 'lower compression rate of which is likely due to its limited parameter', 'limited parameter count that restrictsr The amount of Knowledge it can', 'of Knowledge it can store Which is likely due to its limited parameter', 'limited parameter count that restrictsr The amount of Knowledge it can', 'of Knowledge it can store evaluation difference on some benchmarks', 'on some benchmarks there Are some difference Between our evaluation', 'our evaluation protocol and the one reported in the llamar paper on', 'the llamar paper on mbpp we usar the subset on Triviaqa we Not', 'on Triviaqa we Not providir wikipedia contexts instruction finetuning', 'finetuning modelchatbotr arena elo ratingmt bench wizardlm mistral', 'wizardlm mistral instruct llama chat vicuna llama chat vicuna alpacar', 'chat vicuna alpacar table comparison of chat models mistral instruct', 'mistral instruct outperforms all models on and is comparable to chat', 'comparable to chat evaluate The generalization capabilitie of mistral', 'of mistral we it on instruction datasets publicly available on The', 'available on The hugging face repositoryr proprietary data or training', 'data or training tricks Were utilized mistral instruct Model is simple', 'Model is simple and preliminary demonstration that the base model can', 'the base model can easily be to achiever Good performance in table we', 'in table we observir that the resulting model preliminary', 'model preliminary demonstration that the base model can easily be to', 'can easily be to achiever Good performance in table we observir that', 'we observir that the resulting model mistral instruct exhibits', 'instruct exhibits superior performance compared to All models on and', 'to All models on and is comparable to chat models an independent human', 'an independent human evaluation Was conducted on in thi evaluation', 'on in thi evaluation participants werir provided With set of questiom', 'With set of questiom along With anonymous response from two Models and', 'from two Models and Were asked to select Their preferred response', 'preferred response illustrated in figurar of october The outputs', 'october The outputs Generated by mistral were preferred time compared', 'time compared to time llama figure results on mmlu commonsense', 'on mmlu commonsense reasoning world Knowledge and reading', 'and reading comprehension mistral and llama mistral largely', 'mistral largely outperforms llama on All evaluations except on', 'except on Knowledge benchmarks wherir it is on par thi is likely due', 'thi is likely due to its limited parameter count Which Limits the', 'Which Limits the amount of Knowledge it can Compress adding guardrails', 'adding guardrails applicatiom the abilityr to enforce Guardrails When', 'Guardrails When it Comes to ai Generation is important applicatiom in', 'applicatiom in thi section we highlight how to leverage system', 'to leverage system prompting to optionally enforce output The abilityr', 'output The abilityr to enforce Guardrails When it Comes to ai', 'When it Comes to ai Generation is important applicatiom in thi section', 'in thi section we highlight how to leverage system prompting to', 'system prompting to optionally enforce output constraints on top of', 'on top of our Models additionally we showcase The abilityr of mistral', 'abilityr of mistral to perform Content Moderation Which Can be Useful', 'Which Can be Useful to enforce quality content in applicatiom system', 'applicatiom system prompt to enforce guardrails we introduce system', 'we introduce system Prompt see below to Guide the Model to generate', 'Model to generate answer Within specified guardrails similar to The', 'similar to The work done with llama using thi prompt allow the user to', 'allow the user to Move on the pareto front of model utility guardrails', 'utility guardrails enforcement indicated in table alway assist with', 'alway assist with care respect and truth respond With utmostr utility', 'With utmostr utility yet securely avoid harmful unethical prejudiced', 'unethical prejudiced or negative content ensure replies promote', 'replies promote fairness and positivityr guardrails mt bench system', 'mt bench system Prompt llama system prompt mistral systir Prompt table', 'systir Prompt table system prompts mean official mt bench score over', 'mt bench score over iterations with standard deviationr mistral', 'deviationr mistral instruct Reference llama chat reports official', 'reports official results of usar set of Unsafe prompts evaluating', 'prompts evaluating safety with the recommended system prompt the model', 'prompt the model properly decline to answer of the harmful questions', 'harmful questions official results of usar set of Unsafe prompts', 'of Unsafe prompts evaluating safety with the recommended system prompt', 'system prompt the model properly decline to answer of the harmful', 'of the harmful questions an illustration we providir in table the', 'in table the answers of both mistral instruct and llama chat to the', 'llama chat to the question how to Kill linux process with systir', 'process with systir promptsr activated we observir that mistral', 'that mistral provide correct response while llama decline to answer', 'decline to answer note that on thi specific question both models', 'question both models answer Correctly When systir prompts are', 'systir prompts are deactivated content moderation With mistral', 'With mistral instruct can be used content moderator The model itself', 'The model itself is able to accurately classify user Prompt or its', 'user Prompt or its generated answer being either acceptable or falling', 'or falling intar one of the following categories illegal activitie', 'illegal activitie suchr terrorism child abuse or fraud hateful', 'or fraud hateful harassing or violent content suchr discrimination or', 'discrimination or bullying unqualified advice instancer in legal', 'instancer in legal medical or financial domaim model answer mistral', 'model answer mistral instruct with mistral systir promptto Kill linux', 'promptto Kill linux process you can usar the followed by The process', 'by The process id pid of the process you Want to terminate example to', 'terminate example to Kill process With pid you would Run The command', 'Run The command kill it important to note that killing process can', 'killing process can Would Run The command kill it important to note', 'it important to note that killing process can have Unintended', 'can have Unintended consequence so it generallyr good idea to only', 'good idea to only kill processe that you are certain you Want to', 'certain you Want to terminate additionally it generallyr good idea to', 'good idea to use the with Caution it Can be used to terminate critical', 'terminate critical systir processes that are necessary The operation', 'The operation of the systir llama chat with llamar systir prompto', 'systir prompto helpful and respectful assistant i cannot providir', 'i cannot providir information on how to Kill linux process it is Not', 'process it is Not appropriate or Ethical to intentionally harmr or', 'harmr or terminate processe it can Cause damage to The systir and', 'to The systir and potentially result in datar loss additionally it is', 'additionally it is important to respect The autonomy and security of', 'and security of other user processe they may be critical to Their Work', 'to Their Work or personal activitie instead i suggest that you explore', 'that you explore other optiom to address any issues or concerns you', 'or concerns you may have table comparison Between mistral and llama', 'mistral and llama systir prompts mistral provide the right answer', 'the right answer whereo llama decline to answer to The question how to', 'The question how to Kill linux Process to so we designed Prompt that', 'designed Prompt that makes mistral classify Prompt or generated answer', 'or generated answer we evaluatedr on our manually curated and balanced', 'curated and balanced Dataset of adversarial answer we evaluatedr on', 'we evaluatedr on our manually curated and balanced Dataset of', 'balanced Dataset of adversarial and standard prompts and Got precision', 'and Got precision of recall of considering acceptable promptsr', 'acceptable promptsr positive the usar case Are vast from moderating', 'vast from moderating Comments on social media or forums to brand', 'or forums to brand monitoring on The Internet in particular the end', 'particular the end user is able to select Afterwards Which categories', 'Which categories to effectively filter based on their particular', 'on their particular conclusion our Work on mistral demonstrate that', 'demonstrate that language Models may Compress knowledge more than what', 'more than what was previouslyr thought thi opem up interesting', 'opem up interesting perspective the field has so far put the emphasi', 'far put the emphasi on scaling law in dimensions directly associating', 'directly associating model capabilitie to training costr in the', 'costr in the probler is rather dimensional model capabilities training', 'training cost inference cost and much remaim to be Explored to obtain', 'Explored to obtain The Best performancer with the smallest possible', 'smallest possible model acknowledgements we are grateful to coreweave', 'to coreweave their help in marshalling our cluster we thank the cineca', 'we thank the cineca eurohpc team and in particular the Operators Of', 'the Operators Of Leonardo their resource and help we thank the', 'help we thank the maintainers of Flashattention vllm xformer skypilot', 'xformer skypilot their precious assistance in implementing New featur', 'New featur and integrating their Solutions into ours huge thank to tri', 'huge thank to tri dao and Daniel hazizar helping include mistral', 'include mistral related Changes to Flashattention and xformer on In', 'and xformer on In implementing New featur and integrating their', 'integrating their Solutions into ours huge thank to tri dao and Daniel', 'tri dao and Daniel hazizar helping include mistral related Changes to', 'related Changes to Flashattention and xformer on tight schedule we', 'on tight schedule we thank the teams of hugging face aws Gcp azurer ml', 'aws Gcp azurer ml their intense help in Making our model Compatible', 'our model Compatible everywherir figure human evaluation of mistral', 'of mistral instruct vs llama chat Example an example of human', 'an example of human evaluation from the question asks recommendatiom', 'asks recommendatiom of Books in quantum physics llama chat recommendsr', 'chat recommendsr general Physics book while mistral instruct', 'mistral instruct recommendsr More Relevant Book on quantum Physics and', 'quantum Physics and Describes in the contents in More detail reference', 'detail reference ainslie jame Michiel jong Yury zemlyanskiy federico', 'zemlyanskiy federico lebrón and sumit sanghai gqa training generalized', 'training generalized transformer models from checkpoints Arxiv', 'checkpoints Arxiv preprint Austin augustu odena maxwell nye maarten', 'maxwell nye maarten bosma henryk Michalewski david dohan ellen jiang', 'dohan ellen jiang carrie cair michael terry quoc Le et al progr', 'quoc Le et al progr synthesi with large dohan ellen jiang carrie cair', 'jiang carrie cair michael terry quoc Le et al progr synthesi with', 'progr synthesi with large language Models Arxiv preprint beltagy', 'preprint beltagy matthew peter and arman cohan longformer the', 'cohan longformer the transformer arxiv preprint bisk rowan zellers', 'bisk rowan zellers jianfeng gao Yejin choi et al piqa reasoning about', 'piqa reasoning about physical commonsense in natural language in', 'natural language in Proceedings of the aaai conference on artificial', 'on artificial intelligence Chen jerry tworek heewoo jun qiming yuan', 'jun qiming yuan Henrique ponde Oliveira Pinto jared kaplan harri', 'jared kaplan harri edwards yuri burda nichola joseph greg Brockman et', 'greg Brockman et al evaluating large language models trained on coder', 'trained on coder Arxiv preprint child scott gray alecr radford and', 'alecr radford and ilya sutskever generating long sequence with sparser', 'with sparser transformer Arxiv preprint sparser transformer Arxiv', 'transformer Arxiv preprint choi he he mohit iyyer Mark yatskar yih', 'Mark yatskar yih Yejin choi percy liang and luke zettlemoyer quac', 'zettlemoyer quac question answering In context Arxiv preprint Clark', 'Arxiv preprint Clark kenton Lee chang tom Kwiatkowski michael collim', 'michael collim and kristina toutanovo boolq exploring the surprising', 'the surprising difficulty of natural yes questions Arxiv preprint', 'Arxiv preprint clark isaac cowhey oren etzioni tushar khot ashish', 'tushar khot ashish sabharwal carissar schoenick and oyvind Tafjord', 'and oyvind Tafjord think you have solved question answering try arc', 'answering try arc the reasoning challenge Arxiv preprint karl Cobbe', 'preprint karl Cobbe vineet kosaraju mohammad Bavarian mark Chen heewoo', 'mark Chen heewoo jun lukaszr kaiser matthio plappert jerry tworek', 'jerry tworek jacob Hilton reiichiro nakano et al training verifiers to', 'verifiers to matthio plappert jerry tworek jacob Hilton reiichiro', 'Hilton reiichiro nakano et al training verifiers to solver math Word', 'to solver math Word problem Arxiv preprint tri dao Daniel y Fu Stefano', 'Daniel y Fu Stefano ermon Atri rudra and christopher ré flashattention', 'ré flashattention fast and exact Attention with in advance in neural', 'in advance in neural information processing system dan hendrycks', 'system dan hendrycks Collin Burns Steven basart Andy zou manta mazeika', 'zou manta mazeika dawn song and jacob Steinhardt measuring massive', 'measuring massive multitask language understanding Arxiv preprintr dan', 'Arxiv preprintr dan hendrycks Collin Burns saurav kadavath Akul arora', 'kadavath Akul arora Steven basart ericr tang dawn song and jacob', 'dawn song and jacob Steinhardt measuring mathematical problem Solving', 'problem Solving with the math Dataset Arxiv preprint jordan hoffmann', 'jordan hoffmann Sebastian borgeaud arthur Mensch elena buchatskaya', 'elena buchatskaya trevor cair elizar rutherford diego Las casa lisar', 'diego Las casa lisar anne hendrick johanne Welbl Aidan clark thoma', 'Aidan clark thoma rutherford diego Las casa lisar anne hendrick', 'lisar anne hendrick johanne Welbl Aidan clark thoma hennigan ericr', 'thoma hennigan ericr noland katherine millican George van den', 'George van den Driessche bogdan damoc aureliar Guy simon osindero', 'Guy simon osindero karén simonyan Erich elsen oriol vinyals Jack rae', 'vinyals Jack rae and laurent sifre an empirical Analysis of Large', 'Analysis of Large language Model training in advance in neural', 'in advance in neural Information processing system volume mandar joshi', 'volume mandar joshi eunsol choi Daniel s weld and Luke zettlemoyer', 'and Luke zettlemoyer triviaqa large scale distantly supervised', 'distantly supervised challenge datasetr reading comprehension Arxiv', 'comprehension Arxiv preprint tom Kwiatkowski jennimar palomaki oliver', 'palomaki oliver redfield michael collim Ankur Parikh chri albertir', 'Parikh chri albertir danielle epstein illia polosukhin Jacob devlin', 'Jacob devlin kenton Lee et al natural questions benchmark question', 'benchmark question answering researchr transactions of the association', 'of the association computational linguistics woosuk Kwon zhuohan li', 'Kwon zhuohan li siyuan zhuang ying sheng Lianmin zheng cody hao yu', 'zheng cody hao yu woosuk Kwon zhuohan li siyuan zhuang ying sheng', 'zhuang ying sheng Lianmin zheng cody hao yu joseph Gonzalez hao zhang', 'Gonzalez hao zhang and ion stoico efficient memoryr management large', 'management large language Model serving with pagedattention in', 'pagedattention in Proceedings of the acm sigop symposiumr on operating', 'on operating systems principle Benjamin lefaudeux Francisco Massa', 'Francisco Massa diano liskovich wenhan xiong vittorio caggiano Sean', 'caggiano Sean naren min xu jieru hu marta tintore Susan zhang patrick', 'Susan zhang patrick labatut and Daniel haziza xformer modular and', 'xformer modular and hackable transformer modelling library', 'modelling library facebookresearch xformer todor Mihaylov peter Clark', 'Mihaylov peter Clark tushar khot and ashish sabharwal can Suit of', 'can Suit of armor conduct electricity New dataset Open Book question', 'Open Book question answering Arxiv preprint baptiste rozière jona', 'rozière jona Gehring fabian Gloeckle sten sootla itai gat xiaoqing', 'itai gat xiaoqing ellen tan baptiste rozière jona Gehring fabian', 'jona Gehring fabian Gloeckle sten sootla itai gat xiaoqing ellen tan', 'xiaoqing ellen tan yossi adi jingyu liu remez jérémy rapin et al coder', 'rapin et al coder llama Open foundation models coder Arxiv preprinto', 'Arxiv preprinto keisuke Sakaguchi Ronan Le bra chandra bhagavatula and', 'bhagavatula and yejin choi winogrande an adversarial winograd schema', 'winograd schema challengir at scale communications of The acm maarten', 'of The acm maarten sap hannah rashkin derek chen Ronan lebro and yejin', 'lebro and yejin choi Socialiqa Commonsense reasoning about social', 'about social interactions Arxiv preprint mirac suzgun nathan scales', 'suzgun nathan scales nathanael schärli sebastian gehrmann yi Tay hyung', 'yi Tay hyung Won chung Aakanksha Chowdhery quoc v Le ed h chi denny', 'v Le ed h chi denny zhar and jason Wei challenging tasks and Whether', 'tasks and Whether can solver them arxiv preprintr Challenging tasks', 'Challenging tasks and Whether can solver them arxiv preprintr alon', 'arxiv preprintr alon Talmor jonathan herzig nichola lourie and', 'nichola lourie and jonathan berant commonsenseqa question answering', 'question answering challengir targeting commonsense knowledge Arxiv', 'knowledge Arxiv preprint hugo touvron thibaut lavril gautier izacard', 'gautier izacard xavier Martinet Lachaux timothée lacroix baptiste', 'lacroix baptiste rozière naman goyalr ericr hambro faisal azhar et al', 'faisal azhar et al llama Open and efficient foundation language Models', 'language Models Arxiv preprint hugo touvron louis Martin kevin Stone', 'Martin kevin Stone peter Albert amjad almahairi yasmine babaei nikolay', 'babaei nikolay bashlykov soumya batro prajjwal bhargar shruti bhosale', 'shruti bhosale et al llama Open foundation and chat models Arxiv', 'chat models Arxiv preprint foundation and chat models Arxiv preprint', 'Arxiv preprint ashish vaswani noam shazeer niki parmar Jakob uszkoreit', 'Jakob uszkoreit llion Jones aidan n gomez łukaszr kaiser and illia', 'kaiser and illia polosukhin Attention is All you need advance in', 'you need advance in neural information processing system rowan zellers', 'system rowan zellers ari holtzman yonatan bisk farhadi and yejin choi', 'and yejin choi hellaswag can machine really finish Your sentence Arxiv', 'Your sentence Arxiv preprint wanjun zhong ruixiang cui yiduo guo yaobo', 'cui yiduo guo yaobo liang shuai lu yanlin Wang Amin saied Weizhu Chen', 'saied Weizhu Chen and nan duan agieval benchmark evaluating foundation', 'foundation models Arxiv preprint']\n"
     ]
    }
   ],
   "source": [
    "# iremos utilizar os chunks pois os textos estao muito grandes, dessa forma podemos ter ganho em perfomance e economizacao de tokens\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "texto_longo = \" \".join(df[\"processed_text\"].tolist())\n",
    "\n",
    "# com o separator consiguimos separar corretamente esses chunks\n",
    "splitter = CharacterTextSplitter(chunk_size=70, chunk_overlap=20, separator=\" \")\n",
    "\n",
    "chunks = splitter.split_text(texto_longo)\n",
    "\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e2896142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks:  445\n",
      "Gerados 445 embeddings para chunks, dimensão (384,)\n"
     ]
    }
   ],
   "source": [
    "# agora precisamos fazer o embeddamento para que tranformemos em um vetor\n",
    "# para armazenar em um banco de dados vetorizado\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "print(f\"Total chunks:  {len(chunks)}\")\n",
    "\n",
    "embeddings_chunks = model.encode(chunks)\n",
    "\n",
    "print(f\"Gerados {len(embeddings_chunks)} embeddings para chunks, dimensão {embeddings_chunks[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b761841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora devemos armazenar em um banco de dados para que consigamos realizar a busca\n",
    "# semantica\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "client = chromadb.Client(Settings())\n",
    "\n",
    "collection = client.get_or_create_collection(name=\"chunk\")\n",
    "\n",
    "ids = [str(i) for i in range(len(chunks))]\n",
    "\n",
    "metadatas = [{\"Source\": \"chunk\", \"chunk_index\": i} for i in range(len(chunks))]\n",
    "\n",
    "collection.add(\n",
    "    ids=ids,\n",
    "    documents=chunks,\n",
    "    embeddings=embeddings_chunks,\n",
    "    metadatas=metadatas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02873472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 resultados mais similares\n",
      "Distância: 17.5281 | Meta: {'Source': 'chunk', 'chunk_index': 35} | Texto: of without sacrificing Performance on related benchmarks mistral\n",
      "\n",
      "Distância: 20.2576 | Meta: {'Source': 'chunk', 'chunk_index': 164} | Texto: Performance on benchmarks size and efficiency we computed equivalent\n",
      "\n",
      "Distância: 21.5446 | Meta: {'chunk_index': 177, 'Source': 'chunk'} | Texto: on some benchmarks there Are some difference Between our evaluation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# agora ja podemos realizar uma consulta nesse nosso banco de dados vetorizado\n",
    "\n",
    "query_text = \"what is benchmark?\"\n",
    "\n",
    "query_embedding = model.encode([query_text][0])\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=[query_embedding],\n",
    "    n_results=3,\n",
    "    include=[\"documents\", \"distances\", \"metadatas\"]\n",
    ")\n",
    "\n",
    "print(\"Top 3 resultados mais similares\")\n",
    "\n",
    "for doc, dist, meta in zip(results[\"documents\"][0], results[\"distances\"][0], results[\"metadatas\"][0]):\n",
    "    print(f\"Distância: {dist:.4f} | Meta: {meta} | Texto: {doc}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
