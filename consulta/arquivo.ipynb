{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb1866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importações necessárias\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pdfplumber\n",
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import chromadb\n",
    "import nltk\n",
    "import csv\n",
    "import pandas as pd\n",
    " \n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# 1. Função para ler PDF\n",
    "def ler_pdf(caminho_pdf):\n",
    "    with pdfplumber.open(caminho_pdf) as leitor_pdf:\n",
    "        texto = \"\".join([pagina.extract_text() for pagina in leitor_pdf.pages])\n",
    "        leitor_pdf.close()\n",
    "    return texto.replace(\"\\n\", \" \")\n",
    "\n",
    "# 1.1. Função para ler CSV\n",
    "def ler_csv(caminho_csv):\n",
    "    try:\n",
    "        df = pd.read_csv(caminho_csv)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erro  ao ler CSV: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# 1.2. Função para ler todos os dados de uma coluna do arquivo CSV\n",
    "def processar_linhas_csv(caminho_csv, coluna_texto):\n",
    "    df = pd.read_csv(caminho_csv)\n",
    "    textos_tratados = []\n",
    "    \n",
    "    for texto in df[coluna_texto]:\n",
    "        texto_processado = tratamento_pln(str(texto))\n",
    "        textos_tratados.append(texto_processado)\n",
    "    \n",
    "    return f\"\\n\".join(textos_tratados)\n",
    "\n",
    "# 1.1. Função para ler todos os dados de uma ou mais colunas do arquivo CSV\n",
    "def combinar_colunas_csv(caminho_csv, colunas):\n",
    "    df = pd.read_csv(caminho_csv).to_dict(\"records\") ## transforma uma lista de dicionários\n",
    "    texto_combinado = \"\"\n",
    "\n",
    "    for obj in df:\n",
    "        for coluna in colunas:\n",
    "            texto_combinado += f\"{obj[coluna]} \" ## faz uma linha com os valores das colunas selecionadas\n",
    "        texto_combinado += \"\\n\" \n",
    "    return texto_combinado\n",
    "\n",
    "# 2. Função de pré-processamento de texto\n",
    "def tratamento_pln(texto):\n",
    "    # Carregar modelo e stopwords\n",
    "    nlp = spacy.load(\"pt_core_news_sm\")\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    \n",
    "    # Normalização\n",
    "    texto = texto.lower() ## deixa todas as letras minúsculas \n",
    "    texto = re.sub(r'[^a-zA-Záéíóú\\s]', '', texto) # Remoção de números, pontuações e caracteres especiais, utilizando regex \n",
    "    \n",
    "    # Tokenização e limpeza\n",
    "    doc = nlp(texto) # tokenização do texto\n",
    "    clean_tokens = [token.lemma_ for token in doc \n",
    "                   if token.text not in stop_words and not token.is_punct] # tokens lematizados e sem stop words e pontuações\n",
    "    \n",
    "    return ' '.join(clean_tokens)\n",
    "\n",
    "# 3. Divisão em chunks\n",
    "def criar_chunks(texto, tamanho=30, overlap=10):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=tamanho,\n",
    "        chunk_overlap=overlap\n",
    "    ) # instancia o modelo setando o tamanho dos chunks em 40 com o overlap de 10\n",
    "    return splitter.split_text(texto) # retorna os chunks \n",
    "\n",
    "# 4. Geração de embeddings e armazenamento\n",
    "def criar_banco_vetorial(nome_colecao=\"colecao_teste\"):\n",
    "    # Gerar embeddings\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2') ## instancia o modelo de geração de embeddings\n",
    "    \n",
    "    # Criar banco vetorial\n",
    "    client = chromadb.Client() ## instância o banco de dados\n",
    "    collection = client.create_collection(name=nome_colecao) ## cria a collection\n",
    "    \n",
    "    return collection, model\n",
    "\n",
    "def adicionar_chunks(chunks, collection, model):\n",
    "    embeddings = model.encode(chunks) ## transforma os chunks em embeddings para serem armazenados no banco vetorial\n",
    "    ids = [f\"doc_{i}\" for i in range(len(chunks))] ## Cria os ids dos documentos a partir da quantidade de chunks que serão armazenados\n",
    "    \n",
    "    # Adicionar documentos\n",
    "    collection.add(\n",
    "        documents=chunks,\n",
    "        embeddings=embeddings.tolist(),  \n",
    "        ids=ids\n",
    "    ) ## adiciona os dados vetorizados na collection\n",
    "    return\n",
    "\n",
    "# 5. Função de consulta\n",
    "def consultar_banco(colecao, modelo, consulta, n_resultados=1):\n",
    "    embedding_consulta = modelo.encode([consulta]) ## transforma a consulta em um valor dado vetoriazado para realizar a busca no banco\n",
    "    resultados = colecao.query(\n",
    "        query_embeddings=embedding_consulta.tolist(),\n",
    "        n_results=n_resultados ## quantidade de resultados que serão retornados\n",
    "    )\n",
    "    return resultados\n",
    "\n",
    "\n",
    "def ExibirResultados(resultados):\n",
    "    for i in range(len(resultados['ids'][0])):\n",
    "        print(f\"ID: {resultados['ids'][0][i]}\")\n",
    "        print(f\"Documento: {resultados['documents'][0][i]}\")\n",
    "        print(f\"Distância: {resultados['distances'][0][i]}\")\n",
    "        print(\"-\" * 40)\n",
    "# Fluxo principal\n",
    "\n",
    "\n",
    "print(\"\\n============================== CSV =====================================\\n\")\n",
    "\n",
    "# 1º Passo Extrair texto do CSV\n",
    "texto_csv = combinar_colunas_csv(\"arquivos/people-100.csv\", [\"First Name\", \"Last Name\", \"Job Title\"])\n",
    "\n",
    "# 2º Passo: Pré processar o texto\n",
    "texto_csv_tratado = tratamento_pln(texto=texto_csv)\n",
    "\n",
    "# 3º Passo: Transformar o texto em chunks\n",
    "chunks_csv = criar_chunks(texto_csv_tratado, tamanho=40, overlap=10)\n",
    "\n",
    "# 4º Passo: Criar o banco vetorial e o modelo de embedding\n",
    "colecao_people, modelo1 = criar_banco_vetorial(nome_colecao=\"peolple\")\n",
    "\n",
    "# 5º Passo: Transformar os chunks em embeddings e adicionar ao banco vetorial\n",
    "adicionar_chunks(chunks=chunks_csv, collection=colecao_people, model=modelo1)\n",
    "\n",
    "# 6º Passo: Realizar query no banco de dados\n",
    "resultados_csv = consultar_banco(colecao=colecao_people, modelo=modelo1, consulta=\"Game Developer\", n_resultados=3)\n",
    "ExibirResultados(resultados=resultados_csv)\n",
    "\n",
    "print(\"\\n============================== PDF =====================================\\n\")\n",
    "\n",
    "# 1º Passo Extrair texto do PDF\n",
    "texto_porquinhos = ler_pdf(\"arquivos/os_3_porquinhos.pdf\")\n",
    "\n",
    "# 2º Passo: Pré processar o texto\n",
    "texto_tratado_porquinhos = tratamento_pln(texto=texto_porquinhos)\n",
    "\n",
    "# 3º Passo: Transformar o texto em chunks\n",
    "chunks = criar_chunks(texto_tratado_porquinhos, tamanho=100, overlap=30)\n",
    "\n",
    "# 4º Passo: Criar o banco vetorial e o modelo de embedding\n",
    "colecao, modelo = criar_banco_vetorial(nome_colecao=\"tres_porquinhos\")\n",
    "\n",
    "# 5º Passo: Transformar os chunks em embeddings e adicionar ao banco vetorial\n",
    "adicionar_chunks(chunks=chunks, collection=colecao, model=modelo)\n",
    "\n",
    "# 6º Passo: Realizar query no banco de dados\n",
    "resultados = consultar_banco(colecao=colecao, modelo=modelo, consulta=\"lobo mal assoprou\", n_resultados=3)\n",
    "\n",
    "# # Exibir resultados\n",
    "ExibirResultados(resultados=resultados)    \n",
    "============================== CSV =====================================\n",
    "\n",
    "ID: doc_0\n",
    "Documento: shelby terrell game developer\n",
    "Distância: 0.7823794484138489\n",
    "----------------------------------------\n",
    "ID: doc_39\n",
    "Documento: service engineer\n",
    "Distância: 1.2176902294158936\n",
    "----------------------------------------\n",
    "ID: doc_67\n",
    "Documento: agent\n",
    "Distância: 1.2247304916381836\n",
    "----------------------------------------\n",
    "\n",
    "============================== PDF =====================================\n",
    "\n",
    "ID: doc_47\n",
    "Documento: so saboroso abrir porta ir derrubar tudo   lar vigoroso   gritar luizinho lobo soprar soprar\n",
    "Distância: 1.0531327724456787\n",
    "----------------------------------------\n",
    "ID: doc_35\n",
    "Documento: brincadeira saber assim estar seguro contra lobo mau após algum dia casa joozinho luizinho pron to\n",
    "Distância: 1.141261339187622\n",
    "----------------------------------------\n",
    "ID: doc_55\n",
    "Documento: teto porquinho colocar fogo lareira fa zer labareda queimar rabo lobo   auuu uivar dor lobo correr\n",
    "Distância: 1.230822205543518\n",
    "----------------------------------------\n",
    " "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
